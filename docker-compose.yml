services:
  db:
    image: pgvector/pgvector:pg17
    container_name: olala-db
    restart: unless-stopped
    env_file: .env
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-olala}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      PGDATA: /var/lib/postgresql/data/pgdata
    ports:
      - "5432:5432"
    shm_size: 1gb
    volumes:
      # - ./storage/pgdata:/var/lib/postgresql/data
      # - /home/edu09/workspace/dev/OLaLA-Project/storage/pgdata:/var/lib/postgresql/data
      - /home/edu09/workspace/OLaLA-Project/storage/pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres} -d ${POSTGRES_DB:-olala}"]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "5"

  ollama:
    image: ollama/ollama:latest
    container_name: olala-ollama
    restart: unless-stopped
    env_file: .env
    environment:
      OLLAMA_HOST: 0.0.0.0:11434
    ports:
      - "11434:11434"
    volumes:
      - ./storage/ollama:/root/.ollama
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "5"

  backend:
    build:
      context: ./backend
    container_name: olala-backend
    restart: unless-stopped
    env_file: .env
    environment:
      # Use container_name to avoid any DNS-alias weirdness with service names (db/ollama)
      DB_HOST: olala-db
      DB_PORT: 5432
      DB_NAME: ${POSTGRES_DB:-olala}
      DB_USER: ${POSTGRES_USER:-postgres}
      DB_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      DATABASE_URL: postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@olala-db:5432/${POSTGRES_DB:-olala}
      OLLAMA_URL: http://olala-ollama:11434
      EMBED_MODEL: ${EMBED_MODEL:-nomic-embed-text-v2-moe:latest}
      OLLAMA_TIMEOUT: ${OLLAMA_TIMEOUT:-120}
      SLM_BASE_URL: ${SLM_BASE_URL:-http://olala-ollama:11434}
      SLM1_BASE_URL: ${SLM1_BASE_URL:-http://olala-ollama:11434}
      SLM1_API_KEY: ${SLM1_API_KEY:-ollama}
      SLM1_MODEL: ${SLM1_MODEL:-gemma3:4b}
      SLM1_TIMEOUT_SECONDS: ${SLM1_TIMEOUT_SECONDS:-120}
      SLM1_MAX_TOKENS: ${SLM1_MAX_TOKENS:-768}
      SLM1_TEMPERATURE: ${SLM1_TEMPERATURE:-0.1}
      SLM2_BASE_URL: ${SLM2_BASE_URL:-http://olala-ollama:11434}
      SLM2_API_KEY: ${SLM2_API_KEY:-ollama}
      SLM2_MODEL: ${SLM2_MODEL:-gemma3:4b}
      SLM2_TIMEOUT_SECONDS: ${SLM2_TIMEOUT_SECONDS:-120}
      SLM2_MAX_TOKENS: ${SLM2_MAX_TOKENS:-768}
      SLM2_TEMPERATURE: ${SLM2_TEMPERATURE:-0.1}
      JUDGE_BASE_URL: ${JUDGE_BASE_URL:-http://olala-ollama:11434}
      JUDGE_API_KEY: ${JUDGE_API_KEY:-ollama}
      JUDGE_MODEL: ${JUDGE_MODEL:-gemma3:4b}
      # JUDGE_API_KEY: ${JUDGE_API_KEY:-}
      # JUDGE_MODEL: ${JUDGE_MODEL:-gpt-4.1}
      JUDGE_TIMEOUT_SECONDS: ${JUDGE_TIMEOUT_SECONDS:-120}
      JUDGE_MAX_TOKENS: ${JUDGE_MAX_TOKENS:-1024}
      JUDGE_TEMPERATURE: ${JUDGE_TEMPERATURE:-0.2}
      NAVER_CLIENT_ID: ${NAVER_CLIENT_ID:-}
      NAVER_CLIENT_SECRET: ${NAVER_CLIENT_SECRET:-}
      LOG_DIR: /app/logs
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
    ports:
      - "8080:8080"
    volumes:
      - ./storage/logs/backend:/app/logs
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      db:
        condition: service_healthy
      ollama:
        condition: service_started
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "5"

  web:
    build:
      context: ./web
    container_name: olala-web
    restart: unless-stopped
    ports:
      - "5175:5175"
    depends_on:
      - backend
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "5"

  # ── Chat Backend (FastAPI) ────────────────────────
  chat-db:
    image: postgres:16-alpine
    container_name: olala-chat-db
    restart: unless-stopped
    environment:
      POSTGRES_DB: olala_chat
      POSTGRES_USER: olala
      POSTGRES_PASSWORD: olala
    ports:
      - "5433:5432"
    volumes:
      - chat-postgres-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U olala -d olala_chat"]
      interval: 5s
      timeout: 3s
      retries: 10
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "5"

  redis:
    image: redis:7-alpine
    container_name: olala-redis
    restart: unless-stopped
    command: ["redis-server", "--appendonly", "yes"]
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 10
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "5"

  fastapi:
    build:
      context: ./frontend/backend
      dockerfile: Dockerfile
    container_name: olala-fastapi
    restart: unless-stopped
    environment:
      DATABASE_URL: postgresql+asyncpg://olala:olala@olala-chat-db:5432/olala_chat
      REDIS_URL: redis://olala-redis:6379/0
      CORS_ORIGINS: "*"
      LOG_LEVEL: INFO
    ports:
      - "8000:8000"
    depends_on:
      chat-db:
        condition: service_healthy
      redis:
        condition: service_healthy
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "5"

  # ── Flutter Web (Nginx + reverse proxy) ──────────
  web-flutter:
    build:
      context: ./frontend
      args:
        API_URL: ${FRONTEND_API_URL:-http://localhost:8080}
    container_name: olala-web-flutter
    restart: unless-stopped
    ports:
      - "3000:80"
    depends_on:
      - backend
      - fastapi
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "5"

volumes:
  chat-postgres-data:
  redis-data:
